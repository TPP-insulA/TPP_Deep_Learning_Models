{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: polars in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.25.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: fastexcel in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tomas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastexcel) (19.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/tomas/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-macos (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-macos\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install --upgrade pip\n",
    "%pip install polars numpy scikit-learn matplotlib joblib openpyxl fastexcel tensorflow\n",
    "\n",
    "# For TensorFlow on Mac, you need to install tensorflow-macos\n",
    "%pip install tensorflow-macos tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Concatenate, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import timedelta\n",
    "import openpyxl\n",
    "\n",
    "# Configuración de Matplotlib para evitar errores con Tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes\n",
    "\n",
    "Definicón de las constantes y rutas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sujetos: 54\n"
     ]
    }
   ],
   "source": [
    "# Definición de la ruta del proyecto\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "SUBJECTS_RELATIVE_PATH = \"data/Subjects\"\n",
    "SUBJECTS_PATH = os.path.join(PROJECT_ROOT, SUBJECTS_RELATIVE_PATH)\n",
    "# Crear directorio para resultados si no existe\n",
    "FIGURES_DIR = os.path.join(PROJECT_ROOT, \"figures\", \"lstm\")\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "subject_files = [f for f in os.listdir(SUBJECTS_PATH) if f.startswith(\"Subject\") and f.endswith(\".xlsx\")]\n",
    "print(f\"Total sujetos: {len(subject_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Subject21.xlsx (1/69)...\n",
      "Procesando Subject37.xlsx (2/69)...\n",
      "Procesando Subject17.xlsx (3/69)...\n",
      "Procesando Subject40.xlsx (4/69)...\n",
      "Procesando Subject6.xlsx (5/69)...\n",
      "Procesando Subject7.xlsx (6/69)...\n",
      "Procesando Subject41.xlsx (7/69)...\n",
      "Procesando Subject16.xlsx (8/69)...\n",
      "Procesando Subject36.xlsx (9/69)...\n",
      "Procesando Subject20.xlsx (10/69)...\n",
      "Procesando Subject11.xlsx (11/69)...\n",
      "Procesando Subject46.xlsx (12/69)...\n",
      "Procesando Subject50.xlsx (13/69)...\n",
      "Procesando Subject27.xlsx (14/69)...\n",
      "Procesando Subject31.xlsx (15/69)...\n",
      "Procesando Subject30.xlsx (16/69)...\n",
      "Procesando Subject26.xlsx (17/69)...\n",
      "Procesando Subject1.xlsx (18/69)...\n",
      "Procesando Subject51.xlsx (19/69)...\n",
      "Procesando Subject47.xlsx (20/69)...\n",
      "Procesando Subject10.xlsx (21/69)...\n",
      "Procesando Subject29.xlsx (22/69)...\n",
      "Procesando Subject2.xlsx (23/69)...\n",
      "Procesando Subject52.xlsx (24/69)...\n",
      "Procesando Subject44.xlsx (25/69)...\n",
      "Procesando Subject13.xlsx (26/69)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 5, falling back to string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Subject33.xlsx (27/69)...\n",
      "Procesando Subject25.xlsx (28/69)...\n",
      "Procesando Subject48.xlsx (29/69)...\n",
      "Procesando Subject49.xlsx (30/69)...\n",
      "Procesando Subject24.xlsx (31/69)...\n",
      "Procesando Subject32.xlsx (32/69)...\n",
      "Procesando Subject12.xlsx (33/69)...\n",
      "Procesando Subject45.xlsx (34/69)...\n",
      "Procesando Subject53.xlsx (35/69)...\n",
      "Procesando Subject3.xlsx (36/69)...\n",
      "Procesando Subject28.xlsx (37/69)...\n",
      "Procesando Subject35.xlsx (38/69)...\n",
      "Procesando Subject23.xlsx (39/69)...\n",
      "Procesando Subject8.xlsx (40/69)...\n",
      "Procesando Subject19.xlsx (41/69)...\n",
      "Procesando Subject39.xlsx (42/69)...\n",
      "Procesando Subject4.xlsx (43/69)...\n",
      "Procesando Subject54.xlsx (44/69)...\n",
      "Procesando Subject42.xlsx (45/69)...\n",
      "Procesando Subject15.xlsx (46/69)...\n",
      "Procesando Subject14.xlsx (47/69)...\n",
      "Procesando Subject43.xlsx (48/69)...\n",
      "Procesando Subject5.xlsx (49/69)...\n",
      "Procesando Subject38.xlsx (50/69)...\n",
      "Procesando Subject18.xlsx (51/69)...\n",
      "Procesando Subject9.xlsx (52/69)...\n",
      "Procesando Subject22.xlsx (53/69)...\n",
      "Procesando Subject34.xlsx (54/69)...\n",
      "Muestra de datos procesados combinados:\n",
      "shape: (5, 9)\n",
      "┌────────────┬────────────┬───────────┬─────────┬───┬────────────┬────────────┬───────────┬────────┐\n",
      "│ subject_id ┆ cgm_window ┆ carbInput ┆ bgInput ┆ … ┆ insulinSen ┆ insulinOnB ┆ hour_of_d ┆ normal │\n",
      "│ ---        ┆ ---        ┆ ---       ┆ ---     ┆   ┆ sitivityFa ┆ oard       ┆ ay        ┆ ---    │\n",
      "│ i64        ┆ object     ┆ i64       ┆ i64     ┆   ┆ ctor       ┆ ---        ┆ ---       ┆ f64    │\n",
      "│            ┆            ┆           ┆         ┆   ┆ ---        ┆ f64        ┆ f64       ┆        │\n",
      "│            ┆            ┆           ┆         ┆   ┆ f64        ┆            ┆           ┆        │\n",
      "╞════════════╪════════════╪═══════════╪═════════╪═══╪════════════╪════════════╪═══════════╪════════╡\n",
      "│ 0          ┆ [112 111   ┆ 0         ┆ 167     ┆ … ┆ 54.119548  ┆ 0.0        ┆ 0.565217  ┆ 1.238  │\n",
      "│            ┆ 110 112    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 106 104    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 109 1…     ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│ 0          ┆ [106 114   ┆ 0         ┆ 303     ┆ … ┆ 100.744417 ┆ 0.0        ┆ 0.608696  ┆ 2.015  │\n",
      "│            ┆ 128 124    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 118 110    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 112 1…     ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│ 0          ┆ [281 300   ┆ 0         ┆ 320     ┆ … ┆ 135.384615 ┆ 0.0        ┆ 0.652174  ┆ 1.625  │\n",
      "│            ┆ 234 237    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 256 264    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 272 2…     ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│ 0          ┆ [312 329   ┆ 0         ┆ 217     ┆ … ┆ 218.283582 ┆ 0.0        ┆ 0.695652  ┆ 0.536  │\n",
      "│            ┆ 336 343    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 342 326    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 320 3…     ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│ 0          ┆ [118 115   ┆ 0         ┆ 161     ┆ … ┆ 51.260504  ┆ 0.0        ┆ 0.869565  ┆ 1.19   │\n",
      "│            ┆ 113 114    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 114 114    ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "│            ┆ 120 1…     ┆           ┆         ┆   ┆            ┆            ┆           ┆        │\n",
      "└────────────┴────────────┴───────────┴─────────┴───┴────────────┴────────────┴───────────┴────────┘\n",
      "Total muestras: 44651\n"
     ]
    }
   ],
   "source": [
    "def get_cgm_window(bolus_time, cgm_df: pl.DataFrame, window_hours: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obtiene la ventana de datos CGM para un tiempo de bolo específico.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    bolus_time : datetime\n",
    "        Tiempo del bolo de insulina\n",
    "    cgm_df : pl.DataFrame\n",
    "        DataFrame con datos CGM\n",
    "    window_hours : int, opcional\n",
    "        Horas de la ventana de datos (default: 2)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Ventana de datos CGM o None si no hay suficientes datos\n",
    "    \"\"\"\n",
    "    window_start = bolus_time - timedelta(hours=window_hours)\n",
    "    window = cgm_df.filter(\n",
    "        (pl.col(\"date\") >= window_start) & (pl.col(\"date\") <= bolus_time)\n",
    "    ).sort(\"date\").tail(24)\n",
    "    \n",
    "    if window.height < 24:\n",
    "        return None\n",
    "    return window.get_column(\"mg/dl\").to_numpy()\n",
    "\n",
    "def calculate_iob(bolus_time, basal_df: pl.DataFrame, half_life_hours: float = 4.0) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la insulina activa en el cuerpo (IOB).\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    bolus_time : datetime\n",
    "        Tiempo del bolo de insulina\n",
    "    basal_df : pl.DataFrame\n",
    "        DataFrame con datos de insulina basal\n",
    "    half_life_hours : float, opcional\n",
    "        Vida media de la insulina en horas (default: 4.0)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    float\n",
    "        Cantidad de insulina activa\n",
    "    \"\"\"\n",
    "    if basal_df is None or basal_df.is_empty():\n",
    "        return 0.0\n",
    "    \n",
    "    iob = 0.0\n",
    "    for row in basal_df.iter_rows(named=True):\n",
    "        start_time = row[\"date\"]\n",
    "        duration_hours = row[\"duration\"] / (1000 * 3600)\n",
    "        end_time = start_time + timedelta(hours=duration_hours)\n",
    "        rate = row[\"rate\"] if row[\"rate\"] is not None else 0.9\n",
    "        \n",
    "        if start_time <= bolus_time <= end_time:\n",
    "            time_since_start = (bolus_time - start_time).total_seconds() / 3600\n",
    "            remaining = rate * (1 - (time_since_start / half_life_hours))\n",
    "            iob += max(0.0, remaining)\n",
    "    return iob\n",
    "\n",
    "def process_subject(subject_path: str, idx: int) -> list:\n",
    "    \"\"\"\n",
    "    Procesa los datos de un sujeto.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    subject_path : str\n",
    "        Ruta al archivo del sujeto\n",
    "    idx : int\n",
    "        Índice del sujeto\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    list\n",
    "        Lista de diccionarios con características procesadas\n",
    "    \"\"\"\n",
    "    print(f\"Procesando {os.path.basename(subject_path)} ({idx+1}/{len(SUBJECTS_PATH)})...\")\n",
    "    \n",
    "    try:\n",
    "        cgm_df = pl.read_excel(subject_path, sheet_name=\"CGM\")\n",
    "        bolus_df = pl.read_excel(subject_path, sheet_name=\"Bolus\")\n",
    "        try:\n",
    "            basal_df = pl.read_excel(subject_path, sheet_name=\"Basal\")\n",
    "        except Exception:\n",
    "            basal_df = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar {os.path.basename(subject_path)}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Conversión de fechas\n",
    "    cgm_df = cgm_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    bolus_df = bolus_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    if basal_df is not None:\n",
    "        basal_df = basal_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    \n",
    "    cgm_df = cgm_df.sort(\"date\")\n",
    "\n",
    "    processed_data = []\n",
    "    for row in bolus_df.iter_rows(named=True):\n",
    "        bolus_time = row[\"date\"]\n",
    "        cgm_window = get_cgm_window(bolus_time, cgm_df)\n",
    "        \n",
    "        if cgm_window is not None:\n",
    "            iob = calculate_iob(bolus_time, basal_df)\n",
    "            hour_of_day = bolus_time.hour / 23.0\n",
    "            bg_input = row[\"bgInput\"] if row[\"bgInput\"] is not None else cgm_window[-1]\n",
    "            normal = row[\"normal\"] if row[\"normal\"] is not None else 0.0\n",
    "            \n",
    "            # Cálculo del factor de sensibilidad personalizado\n",
    "            isf_custom = 50.0\n",
    "            if normal > 0 and bg_input > 100:\n",
    "                isf_custom = (bg_input - 100) / normal\n",
    "            \n",
    "            features = {\n",
    "                'subject_id': idx,\n",
    "                'cgm_window': cgm_window,\n",
    "                'carbInput': row[\"carbInput\"] if row[\"carbInput\"] is not None else 0.0,\n",
    "                'bgInput': bg_input,\n",
    "                'insulinCarbRatio': row[\"insulinCarbRatio\"] if row[\"insulinCarbRatio\"] is not None else 10.0,\n",
    "                'insulinSensitivityFactor': isf_custom,\n",
    "                'insulinOnBoard': iob,\n",
    "                'hour_of_day': hour_of_day,\n",
    "                'normal': normal\n",
    "            }\n",
    "            processed_data.append(features)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Ejecución en paralelo\n",
    "all_processed_data = Parallel(n_jobs=-1)(\n",
    "    delayed(process_subject)(\n",
    "        os.path.join(SUBJECTS_PATH, f), \n",
    "        idx\n",
    "    ) for idx, f in enumerate(subject_files)\n",
    ")\n",
    "\n",
    "all_processed_data = [item for sublist in all_processed_data for item in sublist]\n",
    "\n",
    "# Conversión a DataFrame\n",
    "df_processed = pl.DataFrame(all_processed_data)\n",
    "print(\"Muestra de datos procesados combinados:\")\n",
    "print(df_processed.head())\n",
    "print(f\"Total muestras: {len(df_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamiento y Limpieza\n",
    "\n",
    "Verificación de los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificación de valores nulos en df_final:\n",
      "shape: (1, 32)\n",
      "┌───────┬───────┬───────┬───────┬───┬──────────────────────┬────────────────┬─────────────┬────────┐\n",
      "│ cgm_0 ┆ cgm_1 ┆ cgm_2 ┆ cgm_3 ┆ … ┆ insulinSensitivityFa ┆ insulinOnBoard ┆ hour_of_day ┆ normal │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ ---   ┆   ┆ ctor                 ┆ ---            ┆ ---         ┆ ---    │\n",
      "│ u32   ┆ u32   ┆ u32   ┆ u32   ┆   ┆ ---                  ┆ u32            ┆ u32         ┆ u32    │\n",
      "│       ┆       ┆       ┆       ┆   ┆ u32                  ┆                ┆             ┆        │\n",
      "╞═══════╪═══════╪═══════╪═══════╪═══╪══════════════════════╪════════════════╪═════════════╪════════╡\n",
      "│ 0     ┆ 0     ┆ 0     ┆ 0     ┆ … ┆ 0                    ┆ 0              ┆ 0           ┆ 0      │\n",
      "└───────┴───────┴───────┴───────┴───┴──────────────────────┴────────────────┴─────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# División de ventana CGM y otras características\n",
    "cgm_columns = [f'cgm_{i}' for i in range(24)]\n",
    "df_cgm = pl.DataFrame({\n",
    "    col: [row['cgm_window'][i] for row in all_processed_data]\n",
    "    for i, col in enumerate(cgm_columns)\n",
    "}, schema={col: pl.Float64 for col in cgm_columns})\n",
    "\n",
    "# Combinar con otras características\n",
    "df_final = pl.concat([\n",
    "    df_cgm,\n",
    "    df_processed.drop('cgm_window')\n",
    "], how=\"horizontal\")\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"Verificación de valores nulos en df_final:\")\n",
    "df_final = df_final.drop_nulls()\n",
    "print(df_final.null_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de valores NaN:\n",
      "NaN en X_cgm: 0\n",
      "NaN en X_other: 0\n",
      "NaN en y: 0\n"
     ]
    }
   ],
   "source": [
    "# Normalizar características\n",
    "scaler_cgm = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_other = StandardScaler()\n",
    "\n",
    "# Normalizar CGM y reshape para LSTM\n",
    "X_cgm = scaler_cgm.fit_transform(df_final.select(cgm_columns).to_numpy())\n",
    "X_cgm = X_cgm.reshape(X_cgm.shape[0], X_cgm.shape[1], 1)\n",
    "\n",
    "# Normalizar otras características (incluyendo hour_of_day)\n",
    "other_features = ['carbInput', 'bgInput', 'insulinOnBoard', 'insulinCarbRatio', \n",
    "                 'insulinSensitivityFactor', 'subject_id', 'hour_of_day']\n",
    "X_other = scaler_other.fit_transform(df_final.select(other_features).to_numpy())\n",
    "\n",
    "# Etiquetas\n",
    "y = df_final.get_column('normal').to_numpy()\n",
    "\n",
    "# Verificar NaN\n",
    "print(\"\\nVerificación de valores NaN:\")\n",
    "print(f\"NaN en X_cgm: {np.isnan(X_cgm).sum()}\")\n",
    "print(f\"NaN en X_other: {np.isnan(X_other).sum()}\")\n",
    "print(f\"NaN en y: {np.isnan(y).sum()}\")\n",
    "\n",
    "if np.isnan(X_cgm).sum() > 0 or np.isnan(X_other).sum() > 0 or np.isnan(y).sum() > 0:\n",
    "    raise ValueError(\"Valores NaN detectados en X_cgm, X_other o y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División por Sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formas de los conjuntos de datos:\n",
      "Entrenamiento CGM: (33272, 24, 1), Validación CGM: (2743, 24, 1), Prueba CGM: (8636, 24, 1)\n",
      "Entrenamiento Otros: (33272, 7), Validación Otros: (2743, 7), Prueba Otros: (8636, 7)\n",
      "Sujetos de prueba: [ 5 19 32 13 48 49]\n"
     ]
    }
   ],
   "source": [
    "# División por sujeto\n",
    "subject_ids = df_final.get_column('subject_id').unique().to_numpy()\n",
    "train_subjects, temp_subjects = train_test_split(subject_ids, test_size=0.2, random_state=42)\n",
    "val_subjects, test_subjects = train_test_split(temp_subjects, test_size=0.5, random_state=42)\n",
    "\n",
    "train_mask = np.isin(df_final.get_column('subject_id').to_numpy(), train_subjects)\n",
    "val_mask = np.isin(df_final.get_column('subject_id').to_numpy(), val_subjects)\n",
    "test_mask = np.isin(df_final.get_column('subject_id').to_numpy(), test_subjects)\n",
    "\n",
    "X_cgm_train, X_cgm_val, X_cgm_test = X_cgm[train_mask], X_cgm[val_mask], X_cgm[test_mask]\n",
    "X_other_train, X_other_val, X_other_test = X_other[train_mask], X_other[val_mask], X_other[test_mask]\n",
    "y_train, y_val, y_test = y[train_mask], y[val_mask], y[test_mask]\n",
    "subject_test = df_final.filter(pl.lit(test_mask)).get_column('subject_id').to_numpy()\n",
    "\n",
    "print(\"\\nFormas de los conjuntos de datos:\")\n",
    "print(f\"Entrenamiento CGM: {X_cgm_train.shape}, Validación CGM: {X_cgm_val.shape}, Prueba CGM: {X_cgm_test.shape}\")\n",
    "print(f\"Entrenamiento Otros: {X_other_train.shape}, Validación Otros: {X_other_val.shape}, Prueba Otros: {X_other_test.shape}\")\n",
    "print(f\"Sujetos de prueba: {test_subjects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo LSTM\n",
    "def create_lstm_model(cgm_shape: tuple, other_features_shape: tuple) -> Model:\n",
    "    \"\"\"\n",
    "    Crea un modelo LSTM con dos entradas.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    cgm_shape : tuple\n",
    "        Forma de los datos CGM\n",
    "    other_features_shape : tuple\n",
    "        Forma de otras características\n",
    "        \n",
    "    Retorna:\n",
    "    --------\n",
    "    Model\n",
    "        Modelo LSTM compilado\n",
    "    \"\"\"\n",
    "    # Definir las entradas\n",
    "    cgm_input = Input(shape=cgm_shape[1:], name='cgm_input')\n",
    "    other_input = Input(shape=(other_features_shape[1],), name='other_input')\n",
    "\n",
    "    # Capas LSTM apiladas para procesar CGM\n",
    "    lstm_out = LSTM(128, return_sequences=True)(cgm_input)\n",
    "    lstm_out = LSTM(64, return_sequences=False)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dropout(0.2)(lstm_out)\n",
    "\n",
    "    # Combinar con otras características\n",
    "    combined = Concatenate()([lstm_out, other_input])\n",
    "\n",
    "    # Capas densas\n",
    "    dense = Dense(64, activation='relu')(combined)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    output = Dense(1, activation='linear')(dense)\n",
    "\n",
    "    # Crear y compilar modelo\n",
    "    model = Model(inputs=[cgm_input, other_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Función de pérdida personalizada\n",
    "def custom_mse(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Función de pérdida MSE personalizada que penaliza más las sobrepredicciones.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    y_true : tf.Tensor\n",
    "        Valores reales\n",
    "    y_pred : tf.Tensor\n",
    "        Valores predichos\n",
    "        \n",
    "    Retorna:\n",
    "    --------\n",
    "    tf.Tensor\n",
    "        Valor de pérdida\n",
    "    \"\"\"\n",
    "    error = y_true - y_pred\n",
    "    overprediction_penalty = tf.where(error < 0, 2 * tf.square(error), tf.square(error))\n",
    "    return tf.reduce_mean(overprediction_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cgm_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │ cgm_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ other_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ other_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cgm_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m66,560\u001b[0m │ cgm_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m49,408\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ other_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ other_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,608\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,153</span> (473.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,153\u001b[0m (473.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,897</span> (472.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,897\u001b[0m (472.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear y compilar modelo\n",
    "model = create_lstm_model(X_cgm_train.shape, X_other_train.shape)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=custom_mse\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo LSTM...\n",
      "Epoch 1/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 56ms/step - loss: 12.2659 - val_loss: 22.8280\n",
      "Epoch 2/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 105ms/step - loss: 4.4280 - val_loss: 30.1002\n",
      "Epoch 3/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 77ms/step - loss: 3.4670 - val_loss: 2.7306\n",
      "Epoch 4/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 87ms/step - loss: 3.0654 - val_loss: 5.1043\n",
      "Epoch 5/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 83ms/step - loss: 2.9835 - val_loss: 2.8937\n",
      "Epoch 6/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 80ms/step - loss: 2.8829 - val_loss: 1.1392\n",
      "Epoch 7/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 73ms/step - loss: 2.7584 - val_loss: 3.7294\n",
      "Epoch 8/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 76ms/step - loss: 2.7061 - val_loss: 336.7675\n",
      "Epoch 9/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 76ms/step - loss: 2.5463 - val_loss: 48.2544\n",
      "Epoch 10/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 74ms/step - loss: 2.6647 - val_loss: 40.7251\n",
      "Epoch 11/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 70ms/step - loss: 2.5423 - val_loss: 64.4039\n",
      "Epoch 12/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 74ms/step - loss: 2.5738 - val_loss: 5.2764\n",
      "Epoch 13/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 71ms/step - loss: 2.4702 - val_loss: 35.1372\n",
      "Epoch 14/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 67ms/step - loss: 2.6154 - val_loss: 1521.9012\n",
      "Epoch 15/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 70ms/step - loss: 2.3922 - val_loss: 16.9139\n",
      "Epoch 16/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 64ms/step - loss: 2.4717 - val_loss: 1.4125\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo\n",
    "print(\"\\nEntrenando modelo LSTM...\")\n",
    "history = model.fit(\n",
    "    [X_cgm_train, X_other_train],\n",
    "    y_train,\n",
    "    validation_data=([X_cgm_val, X_other_val], y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación del modelo LSTM:\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "\n",
      "Valores eliminados en la evaluación: 0\n",
      "MAE LSTM: 1.14 u. de insulina\n",
      "RMSE LSTM: 2.02 u. de insulina\n",
      "R² LSTM: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "print(\"\\nEvaluación del modelo LSTM:\")\n",
    "y_pred = model.predict([X_cgm_test, X_other_test]).flatten()\n",
    "\n",
    "# Limpiar datos para métricas\n",
    "def clean_predictions(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Limpia predicciones eliminando valores infinitos o NaN.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    y_true : np.ndarray\n",
    "        Valores reales\n",
    "    y_pred : np.ndarray\n",
    "        Valores predichos\n",
    "        \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple\n",
    "        Valores limpios (y_true, y_pred) y número de valores eliminados\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_true)\n",
    "    return y_true[mask], y_pred[mask], np.sum(~mask)\n",
    "\n",
    "# Calcular métricas\n",
    "y_test_clean, y_pred_clean, dropped = clean_predictions(y_test, y_pred)\n",
    "print(f\"\\nValores eliminados en la evaluación: {dropped}\")\n",
    "\n",
    "mae = mean_absolute_error(y_test_clean, y_pred_clean)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))\n",
    "r2 = r2_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "print(f\"MAE LSTM: {mae:.2f} u. de insulina\")\n",
    "print(f\"RMSE LSTM: {rmse:.2f} u. de insulina\")\n",
    "print(f\"R² LSTM: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación por Sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rendimiento por sujeto:\n",
      "Sujeto 5: MAE=0.81, RMSE=1.52, R²=-0.38, Valores eliminados=0\n",
      "Sujeto 19: MAE=2.52, RMSE=3.49, R²=-0.94, Valores eliminados=0\n",
      "Sujeto 32: MAE=0.53, RMSE=0.83, R²=0.86, Valores eliminados=0\n",
      "Sujeto 13: MAE=0.54, RMSE=0.63, R²=0.45, Valores eliminados=0\n",
      "Sujeto 48: MAE=1.03, RMSE=1.39, R²=0.06, Valores eliminados=0\n",
      "Sujeto 49: MAE=3.89, RMSE=5.52, R²=-0.44, Valores eliminados=0\n"
     ]
    }
   ],
   "source": [
    "# Evaluación por sujeto\n",
    "print(\"\\nRendimiento por sujeto:\")\n",
    "for subject_id in test_subjects:\n",
    "    mask = subject_test == subject_id\n",
    "    y_test_sub = y_test[mask]\n",
    "    y_pred_sub = y_pred[mask]\n",
    "    \n",
    "    # Limpiar datos del sujeto\n",
    "    y_test_sub_clean, y_pred_sub_clean, dropped_sub = clean_predictions(y_test_sub, y_pred_sub)\n",
    "    \n",
    "    if len(y_test_sub_clean) > 0:\n",
    "        mae_sub = mean_absolute_error(y_test_sub_clean, y_pred_sub_clean)\n",
    "        rmse_sub = np.sqrt(mean_squared_error(y_test_sub_clean, y_pred_sub_clean))\n",
    "        r2_sub = r2_score(y_test_sub_clean, y_pred_sub_clean)\n",
    "        print(\n",
    "            f\"Sujeto {subject_id}: \"\n",
    "            f\"MAE={mae_sub:.2f}, \"\n",
    "            f\"RMSE={rmse_sub:.2f}, \"\n",
    "            f\"R²={r2_sub:.2f}, \"\n",
    "            f\"Valores eliminados={dropped_sub}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Sujeto {subject_id}: No hay suficientes datos válidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"7779437888process_stream_events\"\n",
      "    while executing\n",
      "\"7779437888process_stream_events\"\n",
      "    (\"after\" script)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización del entrenamiento\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Pérdida del Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de la Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida MSE Personalizada')\n",
    "plt.legend()\n",
    "plt.title('Historial de Entrenamiento LSTM')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Visualización de predicciones\n",
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicción vs. Real (LSTM)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones vs valores reales\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_clean, y_pred_clean, alpha=0.5, label='LSTM')\n",
    "plt.plot([0, 15], [0, 15], 'r--')\n",
    "plt.xlabel('Dosis Real (u. de insulina)')\n",
    "plt.ylabel('Dosis Predicha (u. de insulina)')\n",
    "plt.legend()\n",
    "plt.title('Predicción vs. Real (LSTM)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribución de Residuos (LSTM)')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución de residuos\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test_clean - y_pred_clean\n",
    "plt.hist(residuals, bins=20, alpha=0.5, label='Residuos LSTM')\n",
    "plt.xlabel('Residuo (u. de insulina)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.title('Distribución de Residuos (LSTM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"7757709504process_stream_events\"\n",
      "    while executing\n",
      "\"7757709504process_stream_events\"\n",
      "    (\"after\" script)\n"
     ]
    }
   ],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'predictions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo guardado en: /Users/tomas/Desktop/FIUBA/TPP/TPP_Deep_Learning_Models/models/lstm_model.h5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "model.save(os.path.join(MODELS_DIR, 'lstm_model.h5'))\n",
    "print(f\"\\nModelo guardado en: {os.path.join(MODELS_DIR, 'lstm_model.keras')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
